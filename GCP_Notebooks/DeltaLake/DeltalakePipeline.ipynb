{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_pipeline_module_file = '/home/mlops/airflow/dags/deltalake_pipeline.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/mlops/airflow/dags/deltalake_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_pipeline_module_file}\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.decorators import task\n",
    "\n",
    "# import airflow.example_dags.example_complex.example_python_operator\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "import pyspark\n",
    "from delta import *\n",
    "from delta.tables import *\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import Row\n",
    "from pyspark.sql.functions import explode, collect_list, mean\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from airflow.operators.python import Context\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "spark = None\n",
    "db = None\n",
    "\n",
    "\n",
    "\n",
    "user_metadata_baseline = dict()\n",
    "user_metadata_baseline['pipeline_type'] = 'Apache Airflow Python DAG'\n",
    "user_metadata_baseline['dag_file_location'] = '/home/mlops/airflow/dags/deltalake_pipeline.py'\n",
    "user_metadata_baseline['pipeline_name'] = 'Deltalake Pipeline'\n",
    "user_metadata_baseline['python_version'] = sys.version\n",
    "user_metadata_baseline['env_yaml'] = '/home/mlops/env.yaml'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with DAG(\n",
    "    dag_id=\"DeltalakePipeline\",\n",
    "    description='Collects, processes, and saves Ticketmaster, Spotify and Spotify Userdata to the Deltalake. For more info visit https://concert.raphaelmitas.com/blog',\n",
    "    schedule_interval=None,\n",
    "    start_date= datetime.datetime(year=2022, month=2, day=1)\n",
    ") as dag:\n",
    "\n",
    "    if spark is None:\n",
    "    #Initialize Spark\n",
    "        builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "        spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "    if db is None:\n",
    "        #Initialize Firebase Connection\n",
    "        cred = credentials.Certificate(\"/home/mlops/project/DeltaLake/firebaseServiceAccountKey.json\")\n",
    "        firebase_admin.initialize_app(cred)\n",
    "        db = firestore.client()\n",
    "\n",
    "\n",
    "    #[START GENRE FLOW]\n",
    "    @task(task_id='BRONZE_genre_map_table')\n",
    "    def import_genre_map():\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'BRONZE_genre_map_table'\n",
    "        user_metadata['data_origin'] = 'file:///home/mlops/project/DeltaLake/bronze_data/genre_map.csv'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_genre_map_table'\n",
    "\n",
    "\n",
    "        pandas_df = ps.read_csv('file:///home/mlops/project/DeltaLake/bronze_data/genre_map.csv', ';')\n",
    "        spark_df = pandas_df.to_spark()\n",
    "        spark_df.write.format(\"delta\").mode(\"overwrite\").option(\"userMetadata\", user_metadata).save(\"file:///home/mlops/project/DeltaLake/bronze_data/genre_map_table\")\n",
    "\n",
    "        spark_df.show(5)\n",
    "        return \"SUCCESS\"\n",
    "\n",
    "\n",
    "    @task(task_id='PLATINUM_genre_map_indexed')\n",
    "    def genre_map_with_index():\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'PLATINUM_genre_map_indexed'\n",
    "        user_metadata['data_origin'] = 'file:///home/mlops/project/DeltaLake/bronze_data/genre_map.csv'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_genre_map_table'\n",
    "\n",
    "\n",
    "\n",
    "        genre_map = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/bronze_data/genre_map_table')\n",
    "        renamed_map = genre_map\n",
    "        indexer = StringIndexer(inputCol=\"main_genre_9\", outputCol=\"main_genre_9_index\")\n",
    "        renamed_map = indexer.fit(renamed_map).transform(renamed_map)\n",
    "\n",
    "        indexer = StringIndexer(inputCol=\"main_genre_18\", outputCol=\"main_genre_18_index\")\n",
    "        renamed_map = indexer.fit(renamed_map).transform(renamed_map)\n",
    "\n",
    "        indexer = StringIndexer(inputCol=\"genres\", outputCol=\"genres_index\")\n",
    "        renamed_map = indexer.fit(renamed_map).transform(renamed_map)\n",
    "\n",
    "        renamed_map = renamed_map.withColumn(\"main_genre_9_index\",renamed_map.main_genre_9_index.cast('int'))\n",
    "        renamed_map = renamed_map.withColumn(\"main_genre_18_index\",renamed_map.main_genre_18_index.cast('int'))\n",
    "        renamed_map = renamed_map.withColumn(\"genres_index\",renamed_map.genres_index.cast('int'))\n",
    "        renamed_map.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\"file:///home/mlops/project/DeltaLake/platinum_data/genre_map_indexed\")\n",
    "\n",
    "        renamed_map.show(5)\n",
    "        return \"SUCCESS\"\n",
    "\n",
    "\n",
    "    #[END GENRE FLOW]\n",
    "\n",
    "    #[START SPOTIFY FLOW]\n",
    "    @task(task_id='BRONZE_spotify_user_data_table')\n",
    "    def fetch_spotify_user_data():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'BRONZE_spotify_user_data_table'\n",
    "        user_metadata['data_origin'] = 'firebase_firestore: spotify-user-data'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "\n",
    "\n",
    "        docs = db.collection('spotify-user-data').stream()\n",
    "\n",
    "        def flatten(df):\n",
    "            df = df.withColumn(\"url\", df.external_urls.spotify)\n",
    "            df = df.withColumn(\"followers\", df.followers.total)\n",
    "            df = df.withColumn(\"image_url\", df.images[0].url)\n",
    "\n",
    "            df = df.drop('external_urls', 'images')\n",
    "            return df\n",
    "\n",
    "        spark_df = None\n",
    "\n",
    "        for doc in docs:\n",
    "\n",
    "            user_data = doc.to_dict()\n",
    "            if 'items' in user_data and len(user_data['items']) > 0:\n",
    "                pandas_df = ps.DataFrame(user_data['items'])\n",
    "                pandas_df['uid'] = doc.id\n",
    "                pandas_df['create_time'] = doc.create_time\n",
    "                pandas_df['update_time'] = doc.update_time\n",
    "                pandas_df['read_time'] = doc.read_time\n",
    "\n",
    "                if spark_df is None:\n",
    "\n",
    "                    spark_df = flatten(pandas_df.to_spark())\n",
    "                else:\n",
    "                    # pandas_df.to_spark().show()\n",
    "                    spark_df = spark_df.unionByName(flatten(pandas_df.to_spark()))\n",
    "                    spark_df.count()\n",
    "\n",
    "        if spark_df is not None:\n",
    "            spark_df.show(5)\n",
    "\n",
    "        spark_df.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\"file:///home/mlops/project/DeltaLake/bronze_data/spotify_user_data_table\")\n",
    "\n",
    "        return 'SUCCESS'\n",
    "\n",
    "\n",
    "    @task(task_id='GOLD_spotify_cleansed_table')\n",
    "    def user_data_cleanse():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'GOLD_spotify_cleansed_table'\n",
    "        user_metadata['data_origin'] = 'firebase_firestore: spotify-user-data'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "\n",
    "\n",
    "        spotify = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/bronze_data/spotify_user_data_table')\n",
    "\n",
    "        spotify_cleansed = spotify\n",
    "        spotify_cleansed = spotify_cleansed.filter(F.size(\"genres\") > 0)\n",
    "\n",
    "        spotify_cleansed.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\"file:///home/mlops/project/DeltaLake/gold_data/spotify_cleansed_table\")\n",
    "\n",
    "        spotify_cleansed.show(5)\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    @task(task_id='PLATINUM_spotify_genre_agg_table')\n",
    "    def user_data_aggregation():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'PLATINUM_spotify_genre_agg_table'\n",
    "        user_metadata['data_origin'] = 'firebase_firestore: spotify-user-data'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "\n",
    "\n",
    "        spotify = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/gold_data/spotify_cleansed_table')\n",
    "\n",
    "        genre_map = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/bronze_data/genre_map_table')\n",
    "\n",
    "        #Genre Aggregation\n",
    "        spotify_aggregate = spotify\n",
    "\n",
    "        genre_list = genre_map.to_pandas_on_spark().to_dict('list')\n",
    "\n",
    "        def f(row):\n",
    "            genre_set_9 = set()\n",
    "            genre_set_18 = set()\n",
    "            for x in row.genres:\n",
    "                if x in genre_list['genres']:\n",
    "                    index = genre_list['genres'].index(x)\n",
    "                    genre_set_9.add(genre_list['main_genre_9'][index])\n",
    "                    genre_set_18.add(genre_list['main_genre_18'][index])\n",
    "            row = row.asDict()\n",
    "            row['genres_9'] = list(genre_set_9)\n",
    "            row['genres_18'] = list(genre_set_18)\n",
    "            return Row(**row)\n",
    "\n",
    "        spotify_aggregate = spotify_aggregate.rdd.map(f)\n",
    "        spotify_aggregate = spotify_aggregate.toDF()\n",
    "\n",
    "\n",
    "        #User Aggregation\n",
    "        spotify_unify = spotify_aggregate\n",
    "\n",
    "        spotify_unify_followers = spotify_unify.groupby('uid', 'create_time', 'update_time', 'read_time').agg(mean('followers').alias(\"followers\"))\n",
    "        spotify_unify_popularity = spotify_unify.groupby('uid', 'create_time', 'update_time', 'read_time').agg(mean('popularity').alias(\"popularity\"))\n",
    "\n",
    "        spotify_unify_9 = spotify_unify.select('*', explode(spotify_unify.genres_9).alias(\"genre\"))\n",
    "        spotify_unify_9 = spotify_unify_9.groupby('uid', 'create_time', 'update_time', 'read_time').agg(collect_list('genre').alias(\"genres_9\"))\n",
    "        spotify_unify_18 = spotify_unify.select('*', explode(spotify_unify.genres_18).alias(\"genre\"))\n",
    "        spotify_unify_18 = spotify_unify_18.groupby('uid', 'create_time', 'update_time', 'read_time').agg(collect_list('genre').alias(\"genres_18\"))\n",
    "        spotify_unify = spotify_unify.select('*', explode(spotify_unify.genres).alias(\"genre\"))\n",
    "        spotify_unify = spotify_unify.groupby('uid', 'create_time', 'update_time', 'read_time').agg(collect_list('genre').alias(\"genres\"))\n",
    "\n",
    "        spotify_unify = spotify_unify.join(spotify_unify_9, ['uid', 'create_time', 'update_time', 'read_time'])\\\n",
    "            .join(spotify_unify_18, ['uid', 'create_time', 'update_time', 'read_time'])\\\n",
    "            .join(spotify_unify_followers, ['uid', 'create_time', 'update_time', 'read_time'])\\\n",
    "            .join(spotify_unify_popularity, ['uid', 'create_time', 'update_time', 'read_time'])\n",
    "\n",
    "        def f_agg(row):\n",
    "            row = row.asDict()\n",
    "            row['genres'] = dict(Counter(row['genres']))\n",
    "            row['genres_9'] = dict(Counter(row['genres_9']))\n",
    "            row['genres_18'] = dict(Counter(row['genres_18']))\n",
    "            return Row(**row)\n",
    "\n",
    "        spotify_unify = spotify_unify.rdd.map(f_agg)\n",
    "\n",
    "        spotify_unify = spotify_unify.toDF()\n",
    "\n",
    "\n",
    "        # Extract top genre\n",
    "\n",
    "        spotify_extracted = spotify_unify\n",
    "\n",
    "        def f(row):\n",
    "            row = row.asDict()\n",
    "            highest_number = 0\n",
    "            highest_label = 'undefined'\n",
    "            for genre  in row['genres_9'].items():\n",
    "                if genre[1] > highest_number:\n",
    "                    highest_number = genre[1]\n",
    "                    highest_label = genre[0]\n",
    "            row['genres_1'] = highest_label\n",
    "            return Row(**row)\n",
    "\n",
    "        spotify_extracted = spotify_extracted.rdd.map(f)\n",
    "\n",
    "        spotify_extracted = spotify_extracted.toDF()\n",
    "\n",
    "\n",
    "        #Rename Columns\n",
    "        spotify_renamed = spotify_extracted\n",
    "\n",
    "        spotify_renamed = spotify_renamed.withColumnRenamed(\"genres_9\",\"spotify_genres_9\") \\\n",
    "            .withColumnRenamed(\"genres_18\",\"spotify_genres_18\") \\\n",
    "            .withColumnRenamed(\"uid\",\"spotify_uid\") \\\n",
    "            .withColumnRenamed(\"create_time\",\"spotify_create_time\") \\\n",
    "            .withColumnRenamed(\"update_time\",\"spotify_update_time\") \\\n",
    "            .withColumnRenamed(\"read_time\",\"spotify_read_time\") \\\n",
    "            .withColumnRenamed(\"genres\",\"spotify_genres\") \\\n",
    "            .withColumnRenamed(\"followers\",\"spotify_followers\") \\\n",
    "            .withColumnRenamed(\"popularity\",\"spotify_popularity\") \\\n",
    "            .withColumnRenamed(\"genres_1\",\"spotify_genres_1\")\n",
    "        spotify_renamed.printSchema()\n",
    "\n",
    "        #Save\n",
    "        spotify_renamed.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).option(\"mergeSchema\", \"true\").save(\"file:///home/mlops/project/DeltaLake/platinum_data/spotify_genre_agg_table\")\n",
    "\n",
    "        spotify_renamed.show(5)\n",
    "    #[END SPOTIFY FLOW]\n",
    "\n",
    "\n",
    "    #[START TICKETMASTER FLOW]\n",
    "    @task(task_id='BRONZE_ticketmaster_table')\n",
    "    def ticketmaster_table():\n",
    "        print()\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    @task(task_id='SILBER_ticketmaster_augmented_table')\n",
    "    def ingest_spotify_data():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'SILBER_ticketmaster_augmented_table'\n",
    "        user_metadata['data_description'] = 'Ticketmaster Concert Data'\n",
    "        user_metadata['data_origin'] = 'ticketmaster_api: /discovery/v2/events?latlong=48.7758459%2C9.1829321&segmentId=KZFzniwnSyZfZ7v7nJ&page=40&radius=100'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "        user_metadata['data_augmentation_description'] = 'Spotify Artist Data'\n",
    "        user_metadata['data_augmentation_origin'] = 'Spotify API: https://api.spotify.com/v1/search?q=[ARTIST_NAME]&type=artist&limit=1'\n",
    "\n",
    "        #read deltalake table\n",
    "        ticketmaster = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/bronze_data/ticketmaster_table')\n",
    "\n",
    "        #prepare data\n",
    "        ticketmaster_list = ticketmaster.rdd.collect()\n",
    "        for event in ticketmaster_list:\n",
    "            artist_name = re.split('[&\\-:|]',event.name)[0]\n",
    "\n",
    "\n",
    "        #read spotify data\n",
    "        spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id='7b4d7d2626b04188a79a02ecdda845e2', client_secret='e01be9dfdd854f74bfe0d0af10c5a4ee'))\n",
    "\n",
    "        print(f\"SPOTIPY: {spotify}\")\n",
    "        ticketmaster_df = ps.DataFrame(ticketmaster)\n",
    "\n",
    "        spotify_list = list()\n",
    "        for index, event in ticketmaster_df.iterrows():\n",
    "            artist_name = re.split('[&\\-:|]',event['name'])[0].strip()\n",
    "            if artist_name == \"\":\n",
    "                artist_name = \"asdfghjklö\"\n",
    "            result = spotify.search(artist_name, type='artist', limit=1)\n",
    "            print(f\"RESULT: {result},\\n ARTIST_NAME: {artist_name}\")\n",
    "            if len(result['artists']['items']) > 0:\n",
    "                spotify_list.insert(index, result['artists']['items'][0])\n",
    "            else:\n",
    "                spotify_list.insert(index, {})\n",
    "\n",
    "        spotify_df = ps.DataFrame(spotify_list)\n",
    "\n",
    "        ps.set_option('compute.ops_on_diff_frames', True)\n",
    "        complete_df = ps.concat([spotify_df.rename(columns={\n",
    "            'name': 'spotify_name',\n",
    "            'id': 'spotify_id',\n",
    "            'external_urls': 'spotify_external_urls',\n",
    "            'followers': 'spotify_followers',\n",
    "            'genres': 'spotify_genres',\n",
    "            'href': 'spotify_href',\n",
    "            'images': 'spotify_images',\n",
    "            'popularity': 'spotify_popularity',\n",
    "            'type': 'spotify_type',\n",
    "            'uri': 'spotify_uri'\n",
    "        }), ticketmaster_df], axis=1, join=\"inner\")\n",
    "\n",
    "        spark_df = complete_df.to_spark()\n",
    "        spark_df.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\n",
    "            \"file:///home/mlops/project/DeltaLake/silver_data/ticketmaster_augmented_table\")\n",
    "        spark_df.show(5)\n",
    "\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    @task(task_id='GOLD_ticketmaster_flattened_table')\n",
    "    def ticketmaster_flat():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'GOLD_ticketmaster_flattened_table'\n",
    "        user_metadata['data_description'] = 'Ticketmaster Concert Data'\n",
    "        user_metadata['data_origin'] = 'ticketmaster_api: /discovery/v2/events?latlong=48.7758459%2C9.1829321&segmentId=KZFzniwnSyZfZ7v7nJ&page=40&radius=100'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "        user_metadata['data_augmentation_description'] = 'Spotify Artist Data'\n",
    "        user_metadata['data_augmentation_origin'] = 'Spotify API: https://api.spotify.com/v1/search?q=[ARTIST_NAME]&type=artist&limit=1'\n",
    "\n",
    "\n",
    "        #read ticketmaster_flattened_table\n",
    "        ticketmaster_augmented = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/silver_data/ticketmaster_augmented_table')\n",
    "\n",
    "        #flatten spotify cols\n",
    "        spotify_flattened = ticketmaster_augmented\n",
    "\n",
    "        spotify_flattened = spotify_flattened.withColumn(\"spotify_url\", ticketmaster_augmented.spotify_external_urls.spotify)\n",
    "        spotify_flattened = spotify_flattened.withColumn(\"spotify_followers\", ticketmaster_augmented.spotify_followers.total)\n",
    "        spotify_flattened = spotify_flattened.withColumn(\"spotify_image_url\", ticketmaster_augmented.spotify_images[0].url)\n",
    "\n",
    "        spotify_flattened = spotify_flattened.drop('spotify_external_urls', 'spotify_images')\n",
    "\n",
    "\n",
    "        #flatten ticketmaster cols\n",
    "        ticketmaster_flattened = spotify_flattened\n",
    "\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_date\", ticketmaster_flattened.dates['start']['localDate'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_name\", ticketmaster_flattened._embedded['venues'][0]['name'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_id\", ticketmaster_flattened._embedded['venues'][0]['id'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_url\", ticketmaster_flattened._embedded['venues'][0]['url'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_postal_code\", ticketmaster_flattened._embedded['venues'][0]['postalCode'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_timezone\", ticketmaster_flattened._embedded['venues'][0]['timezone'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_city\", ticketmaster_flattened._embedded['venues'][0]['city'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_city\", regexp_replace('ticketmaster_venue_city', '\\{name=', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_city\", regexp_replace('ticketmaster_venue_city', '}', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_country\", ticketmaster_flattened._embedded['venues'][0]['country'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_country\", regexp_replace('ticketmaster_venue_country', '\\{name=', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_country\", regexp_replace('ticketmaster_venue_country', ',.+', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_address\", ticketmaster_flattened._embedded['venues'][0]['address'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_address\", regexp_replace('ticketmaster_venue_address', '\\{line1=', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_address\", regexp_replace('ticketmaster_venue_address', '}', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_url\", ticketmaster_flattened._embedded['attractions'][0].url)\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_artist_locale\", ticketmaster_flattened._embedded['attractions'][0].locale)\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_latitude\", ticketmaster_flattened._embedded['venues'][0]['location'])\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_longitude\", regexp_replace('ticketmaster_venue_latitude', '.+longitude=', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_longitude\", regexp_replace('ticketmaster_venue_longitude', '}', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_latitude\", regexp_replace('ticketmaster_venue_latitude', '.+latitude=', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_latitude\", regexp_replace('ticketmaster_venue_latitude', ', longitude=.+', \"\"))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_latitude\", ticketmaster_flattened['ticketmaster_venue_latitude'].cast(DoubleType()))\n",
    "        ticketmaster_flattened = ticketmaster_flattened.withColumn(\"ticketmaster_venue_longitude\", ticketmaster_flattened['ticketmaster_venue_longitude'].cast(DoubleType()))\n",
    "\n",
    "\n",
    "        ticketmaster_flattened = ticketmaster_flattened.drop('dates', 'classifications', '_links', '_embedded')\n",
    "\n",
    "\n",
    "        #rename cols\n",
    "        ticketmaster_renamed = ticketmaster_flattened\n",
    "\n",
    "        ticketmaster_renamed = ticketmaster_renamed.withColumnRenamed('name', 'ticketmaster_name')\n",
    "        ticketmaster_renamed = ticketmaster_renamed.withColumnRenamed('id', 'ticketmaster_id')\n",
    "        ticketmaster_renamed = ticketmaster_renamed.withColumnRenamed('locale', 'ticketmaster_locale')\n",
    "        ticketmaster_renamed = ticketmaster_renamed.withColumnRenamed('distance', 'ticketmaster_distance')\n",
    "        ticketmaster_renamed = ticketmaster_renamed.withColumnRenamed('units', 'ticketmaster_units')\n",
    "        ticketmaster_renamed = ticketmaster_renamed.withColumnRenamed('price_min', 'ticketmaster_price_min')\n",
    "        ticketmaster_renamed = ticketmaster_renamed.withColumnRenamed('price_max', 'ticketmaster_price_max')\n",
    "\n",
    "        #save data\n",
    "        ticketmaster_renamed.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\"file:///home/mlops/project/DeltaLake/gold_data/ticketmaster_flattened_table\")\n",
    "\n",
    "        ticketmaster_renamed.show(5)\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    @task(task_id='GOLD_ticketmaster_cleansed_table')\n",
    "    def ticketmaster_cleanse():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'GOLD_ticketmaster_cleansed_table'\n",
    "        user_metadata['data_description'] = 'Ticketmaster Concert Data'\n",
    "        user_metadata['data_origin'] = 'ticketmaster_api: /discovery/v2/events?latlong=48.7758459%2C9.1829321&segmentId=KZFzniwnSyZfZ7v7nJ&page=40&radius=100'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "        user_metadata['data_augmentation_description'] = 'Spotify Artist Data'\n",
    "        user_metadata['data_augmentation_origin'] = 'Spotify API: https://api.spotify.com/v1/search?q=[ARTIST_NAME]&type=artist&limit=1'\n",
    "\n",
    "        #read ticketmaster_flattened_table\n",
    "        ticketmaster = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/gold_data/ticketmaster_flattened_table')\n",
    "\n",
    "        #drop cols\n",
    "        ticketmaster_cleansed = ticketmaster\n",
    "\n",
    "        ticketmaster_cleansed = ticketmaster_cleansed.na.drop(subset=[\"spotify_id\", \"spotify_image_url\"])\n",
    "\n",
    "        #filter\n",
    "        ticketmaster_cleansed = ticketmaster_cleansed.filter(F.size(\"spotify_genres\") > 0)\n",
    "\n",
    "        ticketmaster_cleansed.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\"file:///home/mlops/project/DeltaLake/gold_data/ticketmaster_cleansed_table\")\n",
    "\n",
    "        ticketmaster_cleansed.show(5)\n",
    "\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    @task(task_id='PLATINUM_ticketmaster_genre_agg_table')\n",
    "    def ticketmaster_genre_aggregation():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'PLATINUM_ticketmaster_genre_agg_table'\n",
    "        user_metadata['data_description'] = 'Ticketmaster Concert Data'\n",
    "        user_metadata['data_origin'] = 'ticketmaster_api: /discovery/v2/events?latlong=48.7758459%2C9.1829321&segmentId=KZFzniwnSyZfZ7v7nJ&page=40&radius=100'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "        user_metadata['data_augmentation_description'] = 'Spotify Artist Data'\n",
    "        user_metadata['data_augmentation_origin'] = 'Spotify API: https://api.spotify.com/v1/search?q=[ARTIST_NAME]&type=artist&limit=1'\n",
    "\n",
    "\n",
    "        #read ticketmaster_cleansed_table\n",
    "        ticketmaster = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/gold_data/ticketmaster_cleansed_table')\n",
    "\n",
    "        #read genre_map_table\n",
    "        genre_map = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/bronze_data/genre_map_table')\n",
    "\n",
    "        #genre augmentation\n",
    "        ticketmaster_genre_agg = ticketmaster\n",
    "\n",
    "        genre_list = genre_map.to_pandas_on_spark().to_dict('list')\n",
    "        def f(row):\n",
    "\n",
    "            genre_set_9 = set()\n",
    "            genre_set_18 = set()\n",
    "            for x in row.spotify_genres:\n",
    "                if x in genre_list['genres']:\n",
    "                    index = genre_list['genres'].index(x)\n",
    "                    genre_set_9.add(genre_list['main_genre_9'][index])\n",
    "                    genre_set_18.add(genre_list['main_genre_18'][index])\n",
    "            row = row.asDict()\n",
    "            row['spotify_genres_9'] = list(genre_set_9)\n",
    "            row['spotify_genres_18'] = list(genre_set_18)\n",
    "            return Row(**row)\n",
    "\n",
    "        ticketmaster_genre_agg = ticketmaster_genre_agg.rdd.map(f)\n",
    "        ticketmaster_genre_agg = ticketmaster_genre_agg.toDF()\n",
    "\n",
    "\n",
    "        #save data\n",
    "        ticketmaster_genre_agg.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\"file:///home/mlops/project/DeltaLake/platinum_data/ticketmaster_genre_agg_table\")\n",
    "\n",
    "        ticketmaster_genre_agg.show(5)\n",
    "\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    @task(task_id='PLATINUM_tfx_genre_as_label')\n",
    "    def ticketmaster_genre_as_label():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'PLATINUM_tfx_genre_as_label'\n",
    "        user_metadata['data_description'] = 'Ticketmaster Concert Data'\n",
    "        user_metadata['data_origin'] = 'ticketmaster_api: /discovery/v2/events?latlong=48.7758459%2C9.1829321&segmentId=KZFzniwnSyZfZ7v7nJ&page=40&radius=100'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "        user_metadata['data_augmentation_description'] = 'Spotify Artist Data'\n",
    "        user_metadata['data_augmentation_origin'] = 'Spotify API: https://api.spotify.com/v1/search?q=[ARTIST_NAME]&type=artist&limit=1'\n",
    "\n",
    "        #read ticketmaster_genre_agg_table\n",
    "        ticketmaster = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/platinum_data/ticketmaster_genre_agg_table')\n",
    "\n",
    "        genre_as_label = ticketmaster\n",
    "\n",
    "        #take first genre and set label\n",
    "        genre_as_label = genre_as_label.withColumn('spotify_genres_1', genre_as_label.spotify_genres_9[0])\n",
    "\n",
    "        #save\n",
    "        genre_as_label.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\n",
    "    \"file:///home/mlops/project/DeltaLake/platinum_data/tfx_genre_as_label\")\n",
    "\n",
    "        genre_as_label.show(5)\n",
    "\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    @task(task_id='PLATINUM_ticketmaster_rdy_to_serve')\n",
    "    def ticketmaster_ready_to_serve():\n",
    "\n",
    "        user_metadata = user_metadata_baseline\n",
    "\n",
    "        user_metadata['task_id'] = 'PLATINUM_ticketmaster_rdy_to_serve'\n",
    "        user_metadata['data_description'] = 'Ticketmaster Concert Data'\n",
    "        user_metadata['data_origin'] = 'ticketmaster_api: /discovery/v2/events?latlong=48.7758459%2C9.1829321&segmentId=KZFzniwnSyZfZ7v7nJ&page=40&radius=100'\n",
    "        user_metadata['data_origin_task'] = 'BRONZE_spotify_user_data_table'\n",
    "        user_metadata['data_augmentation_description'] = 'Spotify Artist Data'\n",
    "        user_metadata['data_augmentation_origin'] = 'Spotify API: https://api.spotify.com/v1/search?q=[ARTIST_NAME]&type=artist&limit=1'\n",
    "\n",
    "\n",
    "        #read tfx_genre_as_label\n",
    "        ticketmaster = spark.read.format('delta').load(\n",
    "    'file:///home/mlops/project/DeltaLake/platinum_data/tfx_genre_as_label')\n",
    "\n",
    "        #read genre_map_indexed\n",
    "        genre_map = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/platinum_data/genre_map_indexed')\n",
    "\n",
    "\n",
    "        #select cols for ml\n",
    "        rdy_to_serve = ticketmaster\n",
    "\n",
    "        rdy_to_serve = rdy_to_serve.select('spotify_genres_1', 'spotify_followers', 'spotify_popularity')\n",
    "\n",
    "        #cast to float\n",
    "        rdy_to_serve2 = rdy_to_serve\n",
    "\n",
    "        rdy_to_serve2 = rdy_to_serve2.withColumn('spotify_followers', rdy_to_serve2.spotify_followers.cast('float'))\n",
    "\n",
    "        # index string cols\n",
    "        rdy_to_serve3 = rdy_to_serve2\n",
    "\n",
    "        genre_map_prepared = genre_map.select('main_genre_9', 'main_genre_9_index')\\\n",
    "            .withColumnRenamed('main_genre_9', 'spotify_genres_1')\\\n",
    "            .withColumnRenamed('main_genre_9_index', 'spotify_genres_1_index').distinct()\n",
    "\n",
    "        rdy_to_serve3 = rdy_to_serve3.join(genre_map_prepared, 'spotify_genres_1').drop('spotify_genres_1')\n",
    "\n",
    "        #save\n",
    "        rdy_to_serve3.write.format(\"delta\").mode(\"overwrite\")\\\n",
    "            .option(\"userMetadata\", user_metadata).save(\n",
    "    \"file:///home/mlops/project/DeltaLake/platinum_data/ticketmaster_rdy_to_serve\")\n",
    "\n",
    "        rdy_to_serve3.show(5)\n",
    "\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    #[END TICKETMASTER FLOW]\n",
    "\n",
    "\n",
    "\n",
    "    @task(task_id='save_metadata')\n",
    "    def save_metadata():\n",
    "        delta_meta_data = dict()\n",
    "        delta_meta_data['dag_id'] = dag.dag_id\n",
    "        delta_meta_data['description'] = dag.description\n",
    "        delta_meta_data['start_date'] = dag.start_date\n",
    "        delta_meta_data['end_date'] = dag.end_date\n",
    "        delta_meta_data['schedule_interval'] = dag.schedule_interval\n",
    "\n",
    "        #BRONZE_genre_map_table\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/bronze_data/genre_map_table')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "        #PLATINUM_genre_map_indexed\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/platinum_data/genre_map_indexed')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "\n",
    "        #BRONZE_spotify_user_data_table\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/bronze_data/spotify_user_data_table')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "        #GOLD_spotify_cleansed_table\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/gold_data/spotify_cleansed_table')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "        #PLATINUM_spotify_genre_agg_table\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/platinum_data/spotify_genre_agg_table')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "\n",
    "        #BRONZE_ticketmaster_table\n",
    "\n",
    "        #SILBER_ticketmaster_augmented_table\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/silver_data/ticketmaster_augmented_table')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "        #GOLD_ticketmaster_flattened_table\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/gold_data/ticketmaster_flattened_table')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "        #GOLD_ticketmaster_cleansed_table\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/gold_data/ticketmaster_cleansed_table')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "        #PLATINUM_ticketmaster_genre_agg_table\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/platinum_data/ticketmaster_genre_agg_table')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "        #PLATINUM_tfx_genre_as_label\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/platinum_data/tfx_genre_as_label')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "\n",
    "        #PLATINUM_ticketmaster_rdy_to_serve\n",
    "        delta_table = DeltaTable.forPath(spark, '/home/mlops/project/DeltaLake/platinum_data/ticketmaster_rdy_to_serve')\n",
    "        last_operation_df = delta_table.history(1)\n",
    "        last_operation_df.write.format(\"delta\").mode(\"append\")\\\n",
    "            .option(\"userMetadata\", delta_meta_data).save(\"file:///home/mlops/project/DeltaLake/metadata/metadata_history\")\n",
    "\n",
    "        metadata = spark.read.format('delta').load('file:///home/mlops/project/DeltaLake/metadata/metadata_history')\n",
    "\n",
    "        metadata.show(11)\n",
    "        return 'SUCCESS'\n",
    "\n",
    "    metadata_history = save_metadata()\n",
    "    # spotify_genre_agg_table >> metadata_history\n",
    "    # ticketmaster_rdy_to_serve >> metadata_history\n",
    "\n",
    "\n",
    "\n",
    "    genre_map_table = import_genre_map()\n",
    "    genre_map_indexed = genre_map_with_index()\n",
    "\n",
    "\n",
    "    spotify_user_data_table = fetch_spotify_user_data()\n",
    "    spotify_cleansed_table = user_data_cleanse()\n",
    "    spotify_genre_agg_table = user_data_aggregation()\n",
    "\n",
    "    BRONZE_ticketmaster_table = ticketmaster_table()\n",
    "    ticketmaster_augmented_table = ingest_spotify_data()\n",
    "    ticketmaster_flattened_table = ticketmaster_flat()\n",
    "    ticketmaster_cleansed_table = ticketmaster_cleanse()\n",
    "    ticketmaster_genre_agg_table = ticketmaster_genre_aggregation()\n",
    "    tfx_genre_as_label = ticketmaster_genre_as_label()\n",
    "    ticketmaster_rdy_to_serve = ticketmaster_ready_to_serve()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    genre_map_table >> [genre_map_indexed, spotify_genre_agg_table, ticketmaster_genre_agg_table]\n",
    "    genre_map_indexed >> ticketmaster_rdy_to_serve\n",
    "\n",
    "    spotify_user_data_table >> spotify_cleansed_table >> spotify_genre_agg_table\n",
    "\n",
    "    BRONZE_ticketmaster_table >> ticketmaster_augmented_table >> ticketmaster_flattened_table >> ticketmaster_cleansed_table >> ticketmaster_genre_agg_table >> tfx_genre_as_label >> ticketmaster_rdy_to_serve\n",
    "\n",
    "    ticketmaster_rdy_to_serve >> metadata_history\n",
    "    spotify_genre_agg_table >> metadata_history\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}